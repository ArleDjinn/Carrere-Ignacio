{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UXqJRwEFDHzg",
    "outputId": "19c5253b-6739-41cc-de53-a4e2a1ef290f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.68MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 186kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 628kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.57MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "# Definimos una secuencia de transformaciones para aplicar a las imágenes del dataset.\n",
    "# En este caso, solo convertimos las imágenes a tensores utilizando `ToTensor()`.\n",
    "# Esto es necesario para que las imágenes estén en un formato compatible con PyTorch.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convierte la imagen de un formato PIL o numpy.ndarray a un tensor.\n",
    "])\n",
    "\n",
    "# Cargamos el dataset MNIST de entrenamiento.\n",
    "# `root='./data'` especifica el directorio donde se descargarán los datos si no están presentes.\n",
    "# `train=True` indica que queremos el conjunto de datos de entrenamiento.\n",
    "# `transform=transform` aplica las transformaciones definidas previamente a cada imagen.\n",
    "# `download=True` descarga los datos si no están disponibles en el directorio especificado.\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Creamos un DataLoader que nos permite cargar los datos en lotes pequeños.\n",
    "# `dataset=mnist_dataset` es el dataset que se cargará.\n",
    "# `batch_size=16` indica que cada lote contendrá 16 imágenes y etiquetas.\n",
    "# `shuffle=True` mezcla los datos aleatoriamente en cada época, mejorando la generalización del modelo.\n",
    "data_loader = DataLoader(\n",
    "    mnist_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "# Obtenemos un único lote de datos del DataLoader.\n",
    "# `next(iter(data_loader))` convierte el DataLoader en un iterador y toma el primer lote.\n",
    "# El lote contiene `images` (los tensores de las imágenes) y `labels` (las etiquetas correspondientes).\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "\n",
    "# Plot the images in a grid\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.title(f'Label: {labels[i].item()}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UT7LMM57CqC6",
    "outputId": "698dda5e-9c78-4a2a-b65b-8a22aec7eedc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos el modelo MLP\n",
    "# MLP hereda de nn.Module, lo que permite utilizar las funciones y propiedades de PyTorch\n",
    "# para crear, entrenar y evaluar redes neuronales.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Inicializamos la clase base nn.Module\n",
    "        # Esto habilita funciones esenciales como la gestión de capas y forward pass.\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Capa completamente conectada: de entrada (28x28 píxeles) a 512 neuronas\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        # Capa oculta: de 512 neuronas a 256 neuronas\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # Capa de salida: de 256 neuronas a 10 clases (números del 0 al 9)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "        # Función de activación ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Función de activación ReLU\n",
    "        self.LeakyReLU = nn.LeakyReLU()\n",
    "\n",
    "        # # Función de activación Tanh\n",
    "        # self.tanh = nn.tanh()\n",
    "\n",
    "        # Dropout para evitar sobreajuste, porcentaje de neuronas apagadas.\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # Definimos cómo pasa la información a través de la red\n",
    "    # Este método es obligatorio en las clases que heredan de nn.Module.\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Aplanamos las imágenes (de 28x28 a 1D)\n",
    "        x = self.LeakyReLU(self.fc1(x))  # Aplicamos la primera capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.LeakyReLU(self.fc2(x))  # Aplicamos la segunda capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.fc3(x)             # Aplicamos la capa de salida\n",
    "        return x\n",
    "    \n",
    "    # Si se usase una función sigmoide, tendría que ser aplicada al final después de self.fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/10], Pérdida: 0.2050\n",
      "Época [2/10], Pérdida: 0.4000\n",
      "Época [3/10], Pérdida: 0.0310\n",
      "Época [4/10], Pérdida: 0.0286\n",
      "Época [5/10], Pérdida: 0.0565\n",
      "Época [6/10], Pérdida: 0.0358\n",
      "Época [7/10], Pérdida: 0.0277\n",
      "Época [8/10], Pérdida: 0.0295\n",
      "Época [9/10], Pérdida: 0.0325\n",
      "Época [10/10], Pérdida: 0.0098\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros\n",
    "batch_size = 64       # Tamaño de lote\n",
    "learning_rate = 0.001 # Tasa de aprendizaje\n",
    "epochs = 10           # Número de épocas de entrenamiento\n",
    "\n",
    "# Preprocesamiento y carga de datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                 # Convertimos imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizamos a media 0 y varianza 1\n",
    "])\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)  # Dataset de entrenamiento\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform, download=True)  # Dataset de prueba\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True)  # Dataloader para entrenamiento\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False)  # Dataloader para prueba\n",
    "\n",
    "# Definimos el modelo, la función de pérdida y el optimizador\n",
    "model = MLP()                             # Creamos una instancia del modelo MLP\n",
    "criterion = nn.CrossEntropyLoss()         # Función de pérdida para clasificación\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimizador Adam\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Ponemos el modelo en modo entrenamiento\n",
    "    for images, labels in train_loader:  # Iteramos sobre lotes de datos\n",
    "        optimizer.zero_grad()            # Reiniciamos los gradientes\n",
    "        outputs = model(images)          # Hacemos una predicción con el modelo\n",
    "        loss = criterion(outputs, labels)  # Calculamos la pérdida\n",
    "        loss.backward()                  # Propagamos los gradientes\n",
    "        optimizer.step()                 # Actualizamos los pesos del modelo\n",
    "\n",
    "    # Mostramos la pérdida al final de cada época\n",
    "    print(f\"Época [{epoch+1}/{epochs}], Pérdida: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tTyHa34XCrxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba: 97.53%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Ponemos el modelo en modo evaluación (desactiva Dropout)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Desactivamos el cálculo de gradientes para evaluación\n",
    "    for images, labels in test_loader:  # Iteramos sobre los datos de prueba\n",
    "        outputs = model(images)         # Hacemos predicciones\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Obtenemos la clase con mayor probabilidad\n",
    "        total += labels.size(0)         # Total de muestras evaluadas\n",
    "        correct += (predicted == labels).sum().item()  # Contamos las predicciones correctas\n",
    "\n",
    "# Calculamos y mostramos la precisión del modelo\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy en el conjunto de prueba: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERCEPTRON MULTICAPA\n",
    "\n",
    "## Descripción de Pruebas Realizadas\n",
    "**Claudio Bastias - Ignacio Carrere**\n",
    "\n",
    "1. Prueba Número 1: probamos aumentar las neuronas en la capa dos, manteniendo la congruencia.        \n",
    "        # Capa completamente conectada: de entrada (28x28 píxeles) a 512 neuronas\n",
    "        self.fc1 = nn.Linear(28 * 28, 150)\n",
    "        # Capa oculta: de 512 neuronas a 256 neuronas\n",
    "        # self.fc2 = nn.Linear(150, 300)\n",
    "        # Capa de salida: de 256 neuronas a 10 clases (números del 0 al 9)\n",
    "        # self.fc3 = nn.Linear(300, 10)\n",
    "\n",
    "Tuvo precisión de 97,5%\n",
    "\n",
    "2. Prueba número 2: probamos cambiar la capa uno por 256 neuronas, la segunda por 128 a recomendación de ayudante.\n",
    "Modelo tuvo precisión de 97.06%\n",
    "\n",
    "3. Prueba número 3: cambiamos función de activación de ReLU por LeakyReLU.\n",
    "Accuracy en el conjunto de prueba: 97.74%\n",
    "\n",
    "¿Por qué mejoro el accuracy en este caso?\n",
    "\n",
    "a.- Mayor información aprovechada, al usar LeakyRelu, se pudieron activar más neuronas en capas profundas, permitiendo que la red capatara mayor\n",
    "cantidad de patrones relevantes de los datos en el Modelo. Esto porque ReLU tradicional trunca valores negativos a cero. Si los pesos en el entrenamiento hacen que\n",
    "las entradas a algunas neuronas sean negativas, entonces dejará de actualizarse. LeakyReLU permite una pequeña pendiente para valores negativos en vez de truncarlos a 0, evitando la \"muerte\" de las neuronas.\n",
    "\n",
    "b. Al mejorar la propagacion del gradiente, el modelo pudo ajustar mejor los pesos, lo que se traduce en un mejor desempeño en el conujunto de las pruebas.\n",
    "\n",
    "c. Por último el salto en el accuracy del 97.74% indica que la red neuronal aprovechó mejor la información gracias a este pequeño cambio en la funcion de activación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos y Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay una GPU disponible, de lo contrario usar la CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocesamiento: Definir transformaciones para los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convertir imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar los valores a un rango de [-1, 1]\n",
    "])\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)  # Datos de entrenamiento\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)  # Datos de prueba\n",
    "\n",
    "# Crear DataLoaders para manejar los datos de forma eficiente\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # Loader para entrenamiento (batch de 128, mezclado)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # Loader para prueba (batch de 128, sin mezclar)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, verbose=False, filters_l1=64, filters_l2=128, dropout=0.3, final_layer_size=256):\n",
    "    #def __init__(self, verbose=False, filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128):\n",
    "        super(CNN, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.filters_l1 = filters_l1\n",
    "        self.filters_l2 = filters_l2\n",
    "        self.dropout_rate = dropout\n",
    "        self.final_layer_size = final_layer_size\n",
    "\n",
    "        # Primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Segunda capa convolucional\n",
    "        self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Calcular automáticamente las dimensiones de la capa lineal (fc1)\n",
    "        self.fc1_input_size = self._calculate_fc1_input_size()\n",
    "        \n",
    "        # Primera capa completamente conectada\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, self.final_layer_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(self.final_layer_size, 10)  # Capa de salida para 10 clases (MNIST)\n",
    "\n",
    "    def _calculate_fc1_input_size(self):\n",
    "        \"\"\"\n",
    "        Calcula automáticamente el tamaño de la entrada para la primera capa completamente conectada (fc1).\n",
    "        Simula una pasada con una imagen de prueba de tamaño (1, 28, 28).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # Desactiva gradientes\n",
    "            x = torch.randn(1, 1, 28, 28)  # Tensor ficticio de entrada con tamaño MNIST (batch_size=1)\n",
    "            x = self.pool(torch.relu(self.conv1(x)))  # Aplicar Conv1 -> Pool\n",
    "            x = self.pool(torch.relu(self.conv2(x)))  # Aplicar Conv2 -> Pool\n",
    "            fc1_input_size = x.numel()  # Calcular número total de elementos\n",
    "        return fc1_input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.verbose: \n",
    "            print(f\"Entrada: {x.shape}\")  # Imprime la dimensión de la entrada\n",
    "\n",
    "        # Primera capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv1 y MaxPooling: {x.shape}\")  # Dimensión después de Conv1 y Pool\n",
    "\n",
    "        # Segunda capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv2 y MaxPooling: {x.shape}\")  # Dimensión después de Conv2 y Pool\n",
    "\n",
    "        # Aplanar las características 2D a 1D\n",
    "        x = x.view(-1, self.fc1_input_size)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Aplanamiento: {x.shape}\")  # Dimensión después de Flatten\n",
    "\n",
    "        # Primera capa completamente conectada\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc1): {x.shape}\")  # Dimensión después de fc1\n",
    "\n",
    "        # Aplicar Dropout\n",
    "        x = self.dropout(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Dropout: {x.shape}\")  # Dimensión después de Dropout\n",
    "\n",
    "        # Capa de salida\n",
    "        x = self.fc2(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc2): {x.shape}\")  # Dimensión después de fc2 (salida final)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciación, Entrenamiento del Modelo y su Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2317, Test Accuracy: 0.9824\n",
      "Epoch [2/10], Loss: 0.0666, Test Accuracy: 0.9874\n",
      "Epoch [3/10], Loss: 0.0490, Test Accuracy: 0.9884\n",
      "Epoch [4/10], Loss: 0.0405, Test Accuracy: 0.9903\n",
      "Epoch [5/10], Loss: 0.0328, Test Accuracy: 0.9906\n",
      "Epoch [6/10], Loss: 0.0271, Test Accuracy: 0.9922\n",
      "Epoch [7/10], Loss: 0.0235, Test Accuracy: 0.9923\n",
      "Epoch [8/10], Loss: 0.0212, Test Accuracy: 0.9925\n",
      "Epoch [9/10], Loss: 0.0182, Test Accuracy: 0.9920\n",
      "Epoch [10/10], Loss: 0.0160, Test Accuracy: 0.9911\n",
      "Final Test Accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "\n",
    "# Original\n",
    "# model = CNN(verbose=False, filters_l1=8, filters_l2=32, dropout=0.2, final_layer_size=128).to(device) # Mover el modelo a la GPU/CPU\n",
    "\n",
    "# Opcion 1A\n",
    "# model = CNN(verbose=False, filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128).to(device)\n",
    "# Opcion 1C\n",
    "# model = CNN(verbose=False, filters_l1=32, filters_l2=64, dropout=0.4, final_layer_size=128).to(device)\n",
    "# Opcion 2A\n",
    "# model = CNN(verbose=False, filters_l1=64, filters_l2=128, dropout=0.2, final_layer_size=256).to(device)\n",
    "# Opcion 2B\n",
    "# model = CNN(verbose=False, filters_l1=64, filters_l2=128, dropout=0.3, final_layer_size=256).to(device)\n",
    "# Opcion 2C\n",
    "# model = CNN(verbose=False, filters_l1=64, filters_l2=128, dropout=0.4, final_layer_size=256).to(device)\n",
    "\n",
    "# Opcion 1B = Finalmente elegida.\n",
    "model = CNN(verbose=False, filters_l1=32, filters_l2=64, dropout=0.3, final_layer_size=128).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                    # Función de pérdida para clasificación multiclase\n",
    "\n",
    "# Original (Opción 1B)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizador Adam con tasa de aprendizaje 0.001\n",
    "# Opción 1A\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01) # Optimizador Adam con tasa de aprendizaje 0.01\n",
    "# Opción 2A\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)\n",
    "# Opción 2B\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99)\n",
    "\n",
    "# Definir la función de entrenamiento\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()  # Establecer el modelo en modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:  # Iterar sobre los lotes de datos\n",
    "        images, labels = images.to(device), labels.to(device)  # Mover los datos a la GPU/CPU\n",
    "\n",
    "        optimizer.zero_grad()       # Reiniciar los gradientes\n",
    "        outputs = model(images)     # Paso hacia adelante\n",
    "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "        loss.backward()             # Paso hacia atrás (cálculo de gradientes)\n",
    "        optimizer.step()            # Actualizar los pesos\n",
    "\n",
    "        running_loss += loss.item()  # Acumular la pérdida\n",
    "    return running_loss / len(loader)  # Devolver la pérdida promedio\n",
    "\n",
    "# Definir la función de evaluación\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()  # Establecer el modelo en modo de evaluación\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Deshabilitar el cálculo de gradientes para ahorrar memoria\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Mover datos a la GPU/CPU\n",
    "            outputs = model(images)  # Paso hacia adelante\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones (clase con mayor probabilidad)\n",
    "            total += labels.size(0)  # Contar el número total de ejemplos\n",
    "            correct += (predicted == labels).sum().item()  # Contar las predicciones correctas\n",
    "    return correct / total  # Calcular la precisión\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "num_epochs = 10  # Número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    # Entrenar el modelo y calcular la pérdida\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    # Imprimir los resultados de la época actual\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calcular la precisión final en el conjunto de prueba\n",
    "final_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDES CONVOLUCIONALES\n",
    "\n",
    "### Modificaciones en la arquitectura\n",
    "\n",
    "En el texto se realizan sugerencias para la modificación de la arquitectura: (a) el número de filtros, (b) el número de neuronas en la capa posterior a las capas convolucionales, agregando más capas lineales y (c) el parámetro asociado a dropout.\n",
    "\n",
    "Se testearon los siguientes cambios a la arquitectura:\n",
    "\n",
    "1. **Filtros en las capas.**\n",
    "    - Opción 1: \"filters_l1=32\", \"filters_l2=64\"\n",
    "    - Opción 2: \"filters_l1=64\", \"filters_l2=128\"\n",
    "\n",
    "2. **Neuronas en las Capas lineales.**\n",
    "    - Opción 1: \"final_layer_size=128\"\n",
    "    - Opción 2: \"final_layer_size=256\"\n",
    "\n",
    "3. **Dropouts.**\n",
    "    - Opción A: \"dropout=0.2\"\n",
    "    - Opción B: \"dropout=0.3\"\n",
    "    - Opción C: \"dropout=0.4\"\n",
    "\n",
    "### Resultados\n",
    "\n",
    "Final accuracies:\n",
    "\n",
    "- Opción 1A = 0.9894\n",
    "- Opción 1B = 0.9909\n",
    "- Opción 1C = 0.9923\n",
    "\n",
    "¿El mayor desempeño con el mayor dropout? Probando opción 2, aumentando la capa final y el tamaño de los filtros...\n",
    "\n",
    "- Opción 2A = 0.9930\n",
    "- Opción 2B = 0.9931\n",
    "- Opción 2C = 0.9926\n",
    "\n",
    "Tiempo de 15 minutos aproximadamente. Cerca de tres veces más que la opción uno. Mejor desempeño con dropout=0.3\n",
    "\n",
    "### Conclusión: Elección de Arquitectura\n",
    "\n",
    "La segunda opción, con mayores exigencias computacionales (i.e., más neuronas en las capas lineales y filtros de mayor tamaño), no entrega un modelo significativamente más preciso, tal y como es evaluado por la métrica de precisión total. Debería entregar un mejor output, pero no lo hace ¿Quizás es mi computador que es sólo un CPU? De todas formas, los modelos terminan con una precisión aproximada al 99.2%. El grado de dropout tampoco parece ser un factor muy determinante, por lo menos para este caso.\n",
    "\n",
    "1. **Filtros elegidos =** filters_l1=32, filters_l2=64\n",
    "2. **Cantidad de neuronas =** final_layer_size=128\n",
    "3. **Porcentaje de Dropout =** Opción B, dropout=0.3, dadas las tres opciones rindiendo de manera similar, se escoge esta opción para evitar tanto problemas de generalización como de sobreajuste.\n",
    "\n",
    "Se privilegia la eficiencia computacional y un dropout moderado, considerando lo semejante de los desempeños, apuntando a un equilibrio. Todas estas  pruebas fueron realizadas con el entrenamiento basado en el optimizador Adam con tasa de aprendizaje 0.001\n",
    "\n",
    "## Modificaciones en el entrenamiento\n",
    "\n",
    "\"Al igual que la experimentación realizada con el perceptrón multicapa, compare diferentes algoritmos de optimización para el entrenamiento y evalue el comporramiento del entrenamiento para diferentes valores del learning rate.\"\n",
    "\n",
    "En congruencia con la indicación, se prueban las siguientes opciones, con las condiciones de más arriba (l1=32, l2=64, final_layer_size=128, dropout=0.3):\n",
    "\n",
    "1. **Algortimos de optimización**\n",
    "    - Opción 1: Adam\n",
    "    - Opción 2: RMSProp\n",
    "\n",
    "2. **Learning Rates**:\n",
    "    - Opción A: lr=0.01\n",
    "    - Opción B: lr=0.001\n",
    "\n",
    "## Resultados\n",
    "\n",
    "Final accuracies:\n",
    "\n",
    "- Opción 1A = 0.9789\n",
    "- Opción 1B = 0.9909\n",
    "- Opción 2A = 0.9749\n",
    "- Opción 2B = 0.9911\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "El algoritmo de optimización de RMSProp obtuvo el mejor desempeño y el mejor learning rate fue 0.001 para ambos algoritmos. El tiempo de procesamiento de los procesos fue similar, de entre 5 y 7 minutos por opción. Pareciera ser que el tamaño de las capas lineales y de los filtros parece ser el factor principal en cuanto a la demanda de procesamiento.\n",
    "\n",
    "Para efectos de este ejercicio, en base a la evidencia colectada en este miniproyecto, escogería una **arquitectura con filters_l1=32, filters_l2=64, final_layer_size=128, optmizer = RMSProp con un learning rate = 0.001**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dataAnalisis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
